<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>RSE at Sheffield (Posts by Twin Karmakharm)</title><link>http://rse.shef.ac.uk/</link><description></description><atom:link href="http://rse.shef.ac.uk/authors/twin-karmakharm.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Thu, 10 Jan 2019 10:58:05 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Upcoming Deep Learning Workshop (18th January 2019)</title><link>http://rse.shef.ac.uk/blog/2019-01-18-dli-sheffield-news/</link><dc:creator>Twin Karmakharm</dc:creator><description>&lt;p&gt;We're hosting another &lt;strong&gt;Fundamentals of Deep Learning for Computer Vision&lt;/strong&gt; workshop on the &lt;strong&gt;18th of January&lt;/strong&gt;! &lt;a href="http://rse.shef.ac.uk/training/deeplearning/2019-01-18-dli-sheffield"&gt;More details can be found here&lt;/a&gt;.&lt;/p&gt;</description><guid>http://rse.shef.ac.uk/blog/2019-01-18-dli-sheffield-news/</guid><pubDate>Thu, 20 Dec 2018 10:00:00 GMT</pubDate></item><item><title>Blog articles on our Deep Learning workshops</title><link>http://rse.shef.ac.uk/blog/2018-11-27-dli-blog-articles-dl/</link><dc:creator>Twin Karmakharm</dc:creator><description>&lt;div&gt;&lt;p&gt;We've had a couple of blog articles with mentions of our Deep Learning workshops. One is by Adam Tomkins from the Software Sustainability Institute (&lt;a href="https://software.ac.uk/blog/2018-11-22-dabbling-deep-learning"&gt;link&lt;/a&gt;), and the other by Andrei Roibu, one of our masters student in the Aerospace department  (&lt;a href="http://www.residencelife.co.uk/what-have-you-done-today-i-trained-my-pc-to-learn._60163"&gt;link&lt;/a&gt;). Thank you for the writeup guys!&lt;/p&gt;
&lt;p&gt;For more information on upcoming training events hosted by the RSE group, &lt;a href="https://rse.shef.ac.uk/training/events/"&gt;you can visit this page&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/2018-11-27-dli-blog-articles-dl/</guid><pubDate>Tue, 27 Nov 2018 09:00:00 GMT</pubDate></item><item><title>Upcoming Deep Learning Workshop (18th December 2018)</title><link>http://rse.shef.ac.uk/blog/2018-12-18-dli-sheffield-news/</link><dc:creator>Twin Karmakharm</dc:creator><description>&lt;p&gt;We're hosting another &lt;strong&gt;Fundamentals of Deep Learning for Computer Vision&lt;/strong&gt; workshop on the &lt;strong&gt;18th of December&lt;/strong&gt;! &lt;a href="http://rse.shef.ac.uk/training/deeplearning/2018-12-18-dli-sheffield"&gt;More details can be found here&lt;/a&gt;.&lt;/p&gt;</description><guid>http://rse.shef.ac.uk/blog/2018-12-18-dli-sheffield-news/</guid><pubDate>Thu, 15 Nov 2018 10:00:00 GMT</pubDate></item><item><title>Upcoming Deep Learning Workshop (28th November 2018)</title><link>http://rse.shef.ac.uk/blog/2018-11-28-dli-sheffield-news/</link><dc:creator>Twin Karmakharm</dc:creator><description>&lt;p&gt;We're hosting another &lt;strong&gt;Fundamentals of Deep Learning for Computer Vision&lt;/strong&gt; workshop on the &lt;strong&gt;28th of November&lt;/strong&gt;! &lt;a href="http://rse.shef.ac.uk/training/deeplearning/2018-11-28-dli-sheffield"&gt;More details can be found here&lt;/a&gt;.&lt;/p&gt;</description><guid>http://rse.shef.ac.uk/blog/2018-11-28-dli-sheffield-news/</guid><pubDate>Wed, 31 Oct 2018 10:00:00 GMT</pubDate></item><item><title>Osteolytica Project Wrapup</title><link>http://rse.shef.ac.uk/blog/osteolytica-project-wrapup/</link><dc:creator>Twin Karmakharm</dc:creator><description>&lt;div&gt;&lt;p&gt;As the Osteolytica project undertaken by RSES comes to an end, it’s a good time to review the project.&lt;/p&gt;
&lt;h3&gt;What is Osteolytica?&lt;/h3&gt;
&lt;p&gt;Osteolytica is a software tool for osteolytic lesion analysis developed in collaboration with teams led by Dr. Andrew Chantry from Oncology and Dr. Paul Richmond from RSES. It specialises in the reconstruction and analysis of volumetric bone samples generated by murine myeloma studies and obtained from Micro CT scanners within a research environment.&lt;/p&gt;
&lt;p&gt;The GPU (CUDA) is used to accelerate the reconstruction and analysis process, and additionally, for the rendering and visualization of the bone volumes with ray-tracing.&lt;/p&gt;
&lt;p&gt;Compared to the previous approach which involves the manual counting of osteolytic lesions, Osteolytica offers significant improvements with respect to the accuracy and reproducibility as shown in this &lt;a href="https://doi.org/10.1016/j.bone.2015.10.004"&gt;published paper&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;The reconstruction process&lt;/h3&gt;
&lt;p&gt;The goal of Osteolytica is to determine the surface area missing from the bone as a result of osteolytic lesions without needing to refer to prior samples. In order to do this, Osteolytica performs a bone surface reconstruction in two stages, expansion, and contraction.&lt;/p&gt;
&lt;p&gt;For the expansion stage (&lt;strong&gt;Figure 1&lt;/strong&gt;), volumetric expansion is performed on the bone volume sample. This expansion closes the holes within the sample, generating a water-tight volume that also allows the empty areas inside and outside of the volume to be differentiated.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Expansion process" src="http://rse.shef.ac.uk/images/2018_09_17_osteolytica-project-wrapup/osteolytica-expansion.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; The expansion process shown in 2D. a) Bone volume is shown in black. b) The volume is expanded (red) until all the gaps are enclosed. c) Once the expansion is completed, the inside volume can be filled in and the contraction starts from the expansion border (blue line)&lt;/p&gt;
&lt;p&gt;A contraction process is then performed (&lt;strong&gt;Figure 2&lt;/strong&gt;), starting from the outside of the expanded volume, to reduce the expanded volume and creating a crust that approximately fits the bone sample. Osteolytica also performs localised fitting of this crust surface by performing per-voxel localised contraction (&lt;strong&gt;Figure 3&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;&lt;img alt="Contraction process" src="http://rse.shef.ac.uk/images/2018_09_17_osteolytica-project-wrapup/osteolytica-contraction.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; The contraction process shown in 2D. Contraction starts from the expansion border (blue line) and travels towards the centre of the volume. Deeper green shows higher contraction iteration.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Localised fitting" src="http://rse.shef.ac.uk/images/2018_09_17_osteolytica-project-wrapup/osteolytica-localisedfitting.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; Starting from the crust that forms when the contraction boundary meets bone voxels (green line), each voxel on the crust (green dot) is projected in to the volume. Each crust voxel searches a limited surrounding area to count the number of surrounding bone voxels and will place itself in a location where it finds the highest number of bone voxels in the surrounding.&lt;/p&gt;
&lt;p&gt;The final result from these two processes is the original bone volume that has been wrapped within a watertight crust. Where the crust does not overlap a bone voxel, it is defined as a hole (&lt;strong&gt;Figure 4&lt;/strong&gt; red areas). We can then use this information to approximate the amount of missing surface area of the bone.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Reconstruction results" src="http://rse.shef.ac.uk/images/2018_09_17_osteolytica-project-wrapup/osteolytica-reconstructedvolumes.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 4:&lt;/strong&gt; Osteolytica applied to various types of bone. a, b &amp;amp; c)  The the original bone volumes. d, e &amp;amp; f) Reconstruction of the volumes. The reconstruction is shown in red.&lt;/p&gt;
&lt;h3&gt;Handling High-Resolution Samples&lt;/h3&gt;
&lt;p&gt;While mouse tibia were initially used to as the dataset for testing Osteolytica, the intention is to make the program work with high resolution scans of the entire body. Due to the exponential memory requirement for representing dense volumetric data which can easily exceed the size of a GPU’s memory, Osteolytica was changed to use unified managed CUDA memory. From Nvidia GPU’s Pascal architecture onwards, it allows memory to be allocated that is larger than the memory card as long as there is enough system memory. The process works by automatically fetching from system memory when the code running on the GPU requests it.&lt;/p&gt;
&lt;p&gt;In order to keep texture memory used for visualising the volume interactively small enough to fit within the GPU memory, Osteolytica downscales bone samples to fit the size of a pre-specified maximum rendering volume.&lt;/p&gt;
&lt;h3&gt;Time series scans from longitudinal studies&lt;/h3&gt;
&lt;p&gt;The last new development in Osteolytica is to add an experimental feature to allow comparison of the same set of bone over time. This happens in longitudinal studies that tracks the progression of cancer in response to the administration of a new drug for example.&lt;/p&gt;
&lt;p&gt;While theoretically it should be possible to compare the bone volumes over time period directly, there’s a problem where bone volumes in each scan do not align to each other exactly. The alignment problem was solved by using a local optimisation algorithm (&lt;a href="https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/#cobyla-constrained-optimization-by-linear-approximations"&gt;COBYLA provided in nlopt&lt;/a&gt;) in order to maximise the overlap between the two volumes in the time series. The initial result of this alignment process is shown in &lt;strong&gt;Figure 5&lt;/strong&gt; for two volumes scanned at week 0 and week 3. The white colour shows where the volumes overlap, blue and red colours represent the week 0 sample and week 3 samples respectively that did not overlap. &lt;strong&gt;Figure 5a&lt;/strong&gt; shows the two volumes before alignment and &lt;strong&gt;Figure 5b&lt;/strong&gt; shows the volumes after alignment. In this case it can be seen that there has been bone growth after the administering of drugs and that lesions are starting to be filled in.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Volume alignment" src="http://rse.shef.ac.uk/images/2018_09_17_osteolytica-project-wrapup/osteolytica-alignment.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 5:&lt;/strong&gt; Overlapping week 0 and week 3 volumes. White shows overlap, blue shows week 0 and red is week 0 without overlap. a) Volumes before alignment. b) Volumes after alignment.&lt;/p&gt;
&lt;h3&gt;Future work&lt;/h3&gt;
&lt;p&gt;While the core development of Osteolytica is now complete, the clinical trial is just starting and will run for over a year. Afterwards, the resulting scans will then be processed through Osteolytica to measure the progress of treatment.&lt;/p&gt;
&lt;p&gt;The next iteration of Osteolytica will investigate the use of deep learning to perform bone reconstruction with training dataset generated from a synthetic bone degradation model.&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/osteolytica-project-wrapup/</guid><pubDate>Thu, 04 Oct 2018 11:00:00 GMT</pubDate></item><item><title>Upcoming Deep Learning Workshop</title><link>http://rse.shef.ac.uk/blog/2018-10-23-dli-sheffield-news/</link><dc:creator>Twin Karmakharm</dc:creator><description>&lt;p&gt;We're hosting another &lt;strong&gt;Fundamentals of Deep Learning for Computer Vision&lt;/strong&gt; workshop on the &lt;strong&gt;23rd of October&lt;/strong&gt;! &lt;a href="http://rse.shef.ac.uk/training/deeplearning/2018-10-23-dli-sheffield"&gt;More details can be found here&lt;/a&gt;.&lt;/p&gt;</description><guid>http://rse.shef.ac.uk/blog/2018-10-23-dli-sheffield-news/</guid><pubDate>Wed, 03 Oct 2018 13:00:00 GMT</pubDate></item><item><title>RSE Computing Seminar and Coffee &amp; Cake event 19th June 2018 at 12:00</title><link>http://rse.shef.ac.uk/blog/2018-06-19-rse-computing-seminar-coffe-cake/</link><dc:creator>Twin Karmakharm</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;strong&gt;Both events will be held at COM-G12-Main Lewin, Computer Science Department (ground floor) on the 19th of June, starting from 12:00&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;12:00 - RSE Seminar: Tackling the learning curve of scientific programming&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;By: Dr. Patricio Ortiz&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Talk Abstract:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Programming is part of the curriculum of students of computer science, and it will be complemented with other related subjects to make them knowledgeable on the subject. The situation of a science or engineering student is the opposite; typically they have one course to learn one language, and that language is usually not the one they will first face in real-life situations. This situation has occurred for decades, and it is likely not going to change, but there is a real need to better prepare science and engineering students to face the very steep learning curve of having to start programming as part of an ongoing project or their thesis.
Universities like ours offer excellent facilities like the HPCs supplied by CICS, yet the reality is that many students and young researchers may have never used a Unix based system, let alone a parallel system.&lt;/p&gt;
&lt;p&gt;The book I wrote, "first steps in scientific programmings" aims at facilitating the passage through the learning curve by providing tips based on years of experience and my interaction with students and brilliant young researchers who did not have the opportunity to learn anywhere else the challenges which programming in a scientific environment involve.&lt;/p&gt;
&lt;p&gt;I will briefly describe the points which I think are more important to emphasise, points which I've confirmed as important by interacting with other experienced researchers at the U. of Sheffield, who are trying to provide support for the people starting in this field.&lt;/p&gt;
&lt;p&gt;Link for the book:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://sites.google.com/view/fsscientificprogramming/home"&gt;https://sites.google.com/view/fsscientificprogramming/home&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A supportive link:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://sites.google.com/a/sheffield.ac.uk/rcg/my-blog/research-computing-notes/firststepsinscientificprogramming"&gt;https://sites.google.com/a/sheffield.ac.uk/rcg/my-blog/research-computing-notes/firststepsinscientificprogramming&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Please Register using &lt;a href="https://www.eventbrite.co.uk/e/tackling-the-learning-curve-of-scientific-programming-tickets-46366639868"&gt;Eventbrite&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;13:00 - Coffee and Cake event&lt;/h3&gt;
&lt;p&gt;The Coffe and Cake event is open to everyone and offers a great opportunity to further discuss the topics raised by our speaker. In addition, if you have any particular research software issues or would like to have a general discussion about research software or software in teaching, please come along for an informal chat with the RSE team.&lt;/p&gt;&lt;/div&gt;</description><category>seminar event</category><guid>http://rse.shef.ac.uk/blog/2018-06-19-rse-computing-seminar-coffe-cake/</guid><pubDate>Thu, 31 May 2018 12:00:00 GMT</pubDate></item><item><title>Coffee and Cakes Event</title><link>http://rse.shef.ac.uk/blog/coffee-and-cakes-event-2nd-after/</link><dc:creator>Twin Karmakharm</dc:creator><description>&lt;div&gt;&lt;p&gt;The RSE Sheffield team would like to thank everyone for attending the second Coffee and Cakes Event that was held last Wednesday (31/05/2017). The event provided a great opportunity to hear from researchers all around the University about the software engineering challenges faced within their projects. We hope to use the insights gained from the event to help improve your research workflow in the future.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;To get updates on future RSE events, please join our&lt;/strong&gt; &lt;a href="https://groups.google.com/a/sheffield.ac.uk/forum/#!forum/gpucomputing"&gt;RSE Google Discussion Group&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/coffee-and-cakes-event-2nd-after/</guid><pubDate>Thu, 01 Jun 2017 14:12:12 GMT</pubDate></item><item><title>First GPU Computing Seminar - Towards achieving GPU-native adaptive mesh refinement</title><link>http://rse.shef.ac.uk/blog/2nd-gpu-seminar-amr/</link><dc:creator>Twin Karmakharm</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;img alt="amr" src="http://rse.shef.ac.uk/images/2017_05_30_gpu_seminar_amr.jpg"&gt;&lt;/p&gt;
&lt;p&gt;We've kicked off our first GPU Computing group seminar this year with a talk by &lt;strong&gt;Ania Brown&lt;/strong&gt; from Oxford e-Research Centre titled &lt;strong&gt;"Towards achieving GPU-native adaptive mesh refinement"&lt;/strong&gt; on 30th of May 2017. Adaptive mesh refinement (AMR) is a method for reducing memory cost by varying the accuracy in each region to match the physical characteristics of the simulation, at the cost of increased data structure complexity. Ania described the optimisation and software challenges that need to be considered when implementing AMR on GPUs, based on her experience working on a GPU-native framework for stencil calculations on a tree-based adaptively refined mesh as part of her Master degree.&lt;/p&gt;
&lt;p&gt;There's no offical GPU Computing talks in June but we highly recommend the upcoming talk &lt;strong&gt;"From Democratic Consensus to Cannibalistic Hordes: The Principles of Collective Animal Behaviour"&lt;/strong&gt; by &lt;strong&gt;Prof. Iain Couzin&lt;/strong&gt; on the &lt;strong&gt;29th of June 2017&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;Links and More Information&lt;/h3&gt;
&lt;p&gt;For presentation slides and more information on both of these talks, visit the &lt;a href="http://gpucomputing.shef.ac.uk/seminars/"&gt;GPU Computing seminars&lt;/a&gt; page.&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/2nd-gpu-seminar-amr/</guid><pubDate>Thu, 01 Jun 2017 13:00:00 GMT</pubDate></item></channel></rss>